{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "link                4958\n",
       "name                4958\n",
       "discounted_price    4958\n",
       "previous_price      1910\n",
       "discount_%          1910\n",
       "id                  4958\n",
       "brand               4958\n",
       "ratings             1959\n",
       "reviews_count       1959\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookers_data = pd.read_csv('jumia_scraped_televisions.csv')\n",
    "cookers_data.head(100)\n",
    "duplicates = cookers_data[cookers_data.duplicated()]\n",
    "duplicates.count()\n",
    "#len(cookers_data)\n",
    "# cookers_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on the 'id' column, keeping the first occurrence\n",
    "cookers_data = cookers_data.drop_duplicates(subset='id', keep='last')\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "cookers_data.to_csv('cleaned_jumia_scraped_televisions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 2 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 3 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 4 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 5 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 6 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 7 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 8 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 9 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 10 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 11 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 12 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 13 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 14 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 15 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 16 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 17 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 18 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 19 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 20 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 21 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 22 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 23 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 24 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 25 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 26 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 27 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 28 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 29 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 30 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 31 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 32 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 33 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 34 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 35 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 36 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 37 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 38 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 39 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 40 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 41 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 42 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 43 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 44 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 45 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 46 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 47 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 48 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 49 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 50 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraped 5056 products from https://www.jumia.co.ke/televisions/#catalog-listing and saved them to 'jumia_scraped_televisions.csv'.\n",
      "Scraping page 1 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 2 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 3 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 4 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 5 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 6 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 7 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 8 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 9 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 10 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 11 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 12 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 13 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 14 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 15 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 16 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 17 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 18 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 19 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 20 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 21 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 22 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 23 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 24 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 25 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 26 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 27 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 28 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 29 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 30 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 31 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 32 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 33 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 34 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 35 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 36 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 37 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 38 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 39 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 40 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 41 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 42 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 43 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 44 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 45 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 46 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 47 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 48 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 49 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraping page 50 from https://www.jumia.co.ke/home-cooking-appliances-cookers/...\n",
      "Scraped 2009 products from https://www.jumia.co.ke/home-cooking-appliances-cookers/ and saved them to 'jumia_scraped_cookers.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "# User-Agent headers for requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# List of URLs to scrape (only one URL for televisions now)\n",
    "url1 = 'https://www.jumia.co.ke/televisions/#catalog-listing'  # Updated to televisions\n",
    "url3 = 'https://www.jumia.co.ke/home-cooking-appliances-cookers/'  # Remains unchanged\n",
    "\n",
    "urls = [url1, url3]  # Removed the duplicate url2\n",
    "\n",
    "# Function to get the last page number\n",
    "def get_last_page_number(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "        return 1  # Default to 1 if the request fails\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the 'Last Page' link using its aria-label attribute\n",
    "    last_page_link = soup.find('a', attrs={'aria-label': 'Last Page'})\n",
    "    \n",
    "    if last_page_link and 'href' in last_page_link.attrs:\n",
    "        last_page_url = last_page_link['href']\n",
    "        try:\n",
    "            page_number = last_page_url.split('?page=')[1].split('#')[0]\n",
    "            return int(page_number)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting last page number: {e}\")\n",
    "            return 1  # Default to 1 if error occurs\n",
    "    else:\n",
    "        print(\"Last page link not found.\")\n",
    "        return 1  # Default to 1 page if no last page is found\n",
    "\n",
    "# Function to scrape product details from a given URL\n",
    "def scrape_product_details(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the webpage: {url}. Status code: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    products = soup.find_all('a', class_='core')\n",
    "\n",
    "    product_details = []\n",
    "\n",
    "    for product in products:\n",
    "        # Extract product link (relative URL)\n",
    "        link = product['href'] if 'href' in product.attrs else None\n",
    "        # Complete the URL if the link is relative\n",
    "        link = f\"https://www.jumia.co.ke{link}\" if link and link.startswith('/') else link\n",
    "        \n",
    "        # Extract product name (from the 'name' div)\n",
    "        name = product.get('data-gtm-name', \"N/A\")  # Extract from the 'data-gtm-name' attribute\"\n",
    "        \n",
    "        # Extract product price (actual price) from the 'prc' div\n",
    "        price = product.find('div', class_='prc').get_text(strip=True) if product.find('div', class_='prc') else \"N/A\"\n",
    "        \n",
    "        # Extract old price (if available) from the 'old' div or alternative span format\n",
    "        old_price = product.find('div', class_='old').get_text(strip=True) if product.find('div', class_='old') else \\\n",
    "                    product.find('span', class_='-tal -gy5 -lthr -fs16 -pvxs -ubpt').get_text(strip=True) if \\\n",
    "                    product.find('span', class_='-tal -gy5 -lthr -fs16 -pvxs -ubpt') else \"N/A\"\n",
    "        \n",
    "        # Extract discount (if available) from the 'bdg _dsct _sm' div or span with data-disc attribute\n",
    "        discount = product.find('div', class_='bdg _dsct _sm').get_text(strip=True) if product.find('div', class_='bdg _dsct _sm') else \\\n",
    "                  product.find('span', attrs={'data-disc': True}).get_text(strip=True) if \\\n",
    "                  product.find('span', attrs={'data-disc': True}) else \"N/A\"\n",
    "        \n",
    "        # Extract item ID (from data-gtm-id attribute)\n",
    "        item_id = product.get('data-gtm-id', \"N/A\")\n",
    "        \n",
    "        # Extract item brand (from data-gtm-brand attribute)\n",
    "        item_brand = product.get('data-gtm-brand', \"N/A\")\n",
    "        \n",
    "        # Extract the stars rating (from the 'stars _m _al' or 'stars _s' class)\n",
    "        stars_rating = product.find('div', class_='stars _m _al') or product.find('div', class_='stars _s')\n",
    "        if stars_rating:\n",
    "            rating = stars_rating.get_text(strip=True).split(\" out of \")[0]  # Extract the rating value (e.g., \"3.9\")\n",
    "        else:\n",
    "            rating = \"N/A\"\n",
    "        \n",
    "        # Extract reviews count (from the 'rev' class or 'verified ratings' link)\n",
    "        reviews = product.find('div', class_='rev')\n",
    "        if reviews:\n",
    "            reviews_count = reviews.get_text(strip=True).split('(')[-1].replace(')', '')  # Extract the review count (e.g., \"798\")\n",
    "        else:\n",
    "            reviews_link = product.find('a', class_='-plxs _more')\n",
    "            reviews_count = reviews_link.get_text(strip=True).split('(')[-1].replace(')', '') if reviews_link else \"N/A\"\n",
    "        \n",
    "        # Store all the extracted product details\n",
    "        product_details.append({\n",
    "            'link': link,\n",
    "            'name': name,\n",
    "            'discounted_price': price,\n",
    "            'previous_price': old_price,\n",
    "            'discount_%': discount,\n",
    "            'id': item_id,\n",
    "            'brand': item_brand,\n",
    "            'ratings': rating,\n",
    "            'reviews_count': reviews_count\n",
    "        })\n",
    "    \n",
    "    return product_details\n",
    "\n",
    "# Iterate over all URLs to scrape data and save to a CSV file\n",
    "for url in urls:\n",
    "    # Get the last page number for the current URL\n",
    "    last_page = get_last_page_number(url)\n",
    "\n",
    "    # Initialize an empty list to store all products\n",
    "    products_list = []\n",
    "\n",
    "    # Iterate through all pages from 1 to the last page\n",
    "    for page_num in range(1, last_page + 1):\n",
    "        page_url = f\"{url}?page={page_num}#catalog-listing\"\n",
    "        print(f\"Scraping page {page_num} from {url}...\")\n",
    "        \n",
    "        # Scrape the products from the current page\n",
    "        products = scrape_product_details(page_url)\n",
    "        products_list.extend(products)  # Add the scraped products to the main list\n",
    "\n",
    "        # Sleep for a random time between requests to avoid overwhelming the server\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    # Determine the output CSV file name based on the URL\n",
    "    if url == url1:\n",
    "        csv_filename = 'jumia_scraped_televisions.csv'  # Updated filename for televisions\n",
    "    else:\n",
    "        csv_filename = 'jumia_scraped_cookers.csv'\n",
    "\n",
    "    # Save the scraped product details to a CSV file\n",
    "    with open(csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[ \n",
    "            'link', 'name', 'discounted_price', 'previous_price', 'discount_%', 'id', 'brand', 'ratings', 'reviews_count'\n",
    "        ])\n",
    "        writer.writeheader()  # Write the header row\n",
    "        \n",
    "        for product in products_list:\n",
    "            writer.writerow(product)\n",
    "\n",
    "    print(f\"Scraped {len(products_list)} products from {url} and saved them to '{csv_filename}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
