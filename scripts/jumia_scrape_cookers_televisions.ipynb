{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests # make HTTP requests to fetch web pages content\n",
    "from bs4 import BeautifulSoup # parse HTML and XML docs for easier data extraction\n",
    "import csv # write scraped data into CSV file\n",
    "import time # introduce delays between requests to avoid server overload\n",
    "import re #regular expression\n",
    "import random # vary time delays to simulate human-like behaviour\n",
    "import psycopg2 #py package to interact with PostgreSQL\n",
    "from psycopg2 import sql\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Webscraping Page: Jumia**\n",
    "\n",
    "_Products to scrape:_  \n",
    "1. Tvs \n",
    "    * Smart\n",
    "    * Digital\n",
    "2. Cookers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request url\n",
    "url1 = 'https://www.jumia.co.ke/televisions/#catalog-listing' # TVs url\n",
    "url2 = 'https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing' # Cookers url\n",
    "\n",
    "# User-Agent headers for automating requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check url status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://www.jumia.co.ke/televisions/#catalog-listing - status: 200\n",
      "url: https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing - status: 200\n",
      "All pages retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Sending GET requests to each URL and check response\n",
    "def check_response(urls, headers):\n",
    "    # Output the status code of each response\n",
    "    for url in urls:\n",
    "        try:\n",
    "            response =requests.get(url, headers=headers)\n",
    "            print(f\"url: {response.url} - status: { response.status_code}\")\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "                return 1  # Return 1 if the request fails\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            # Handle GET request exceptions (timeout, connection/http errors etc.)\n",
    "            print(f\"An error occured: {e}\")\n",
    "            return 1  # Return 1 if an error occurs during the request\n",
    "        \n",
    "    return 0  # Return 0 if no error\n",
    "\n",
    "# List of urls\n",
    "urls = [url1, url2]\n",
    "responses = check_response(urls, headers=headers) # Check all url GET requests responses\n",
    "\n",
    "# Check result\n",
    "if responses == 0:\n",
    "    print(\"All pages retrieved successfully.\")\n",
    "else:\n",
    "    print(\"Some pages failed to load.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that the webpages are paginated, there is need to navigatethrough, and retrieve data from each page.\n",
    "The last page in the page numbers is identified, then all pages are iterated.\n",
    "\n",
    "The pagination URL parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get the last page number\n",
    "def get_last_page_number(urls, headers):\n",
    "    \"\"\"\n",
    "    get the last page number in a catalog listing for pagination iteration\n",
    "\n",
    "    args:\n",
    "        urls: webpage URL or URLs\n",
    "        headers: User-Agent headers\n",
    "    \"\"\"\n",
    "    # Parse webpage content with BeautifulSoup\n",
    "    #for url in urls:\n",
    "    response =requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find link for last page using its aria-label attribute\n",
    "    last_page_link = soup.find('a', attrs={'aria-label': 'Last Page'})\n",
    "\n",
    "    if last_page_link and 'href' in last_page_link.attrs:\n",
    "        last_page_url =last_page_link['href']\n",
    "        try:\n",
    "            page_number = last_page_url.split('?page=')[1].split('#')[0]\n",
    "            return int(page_number)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting last page number: {e}\")\n",
    "            return 1  # Default to 1 if error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL: https://www.jumia.co.ke/televisions/#catalog-listing\n",
      "Scraping page 1 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 2 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 3 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 4 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 5 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 6 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 7 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 8 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 9 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 10 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 11 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 12 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 13 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 14 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 15 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 16 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 17 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 18 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 19 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 20 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 21 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 22 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 23 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 24 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 25 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 26 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 27 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 28 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 29 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 30 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 31 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 32 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 33 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 34 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 35 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 36 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 37 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 38 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 39 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 40 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 41 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 42 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 43 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 44 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 45 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 46 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 47 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 48 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 49 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Scraping page 50 from https://www.jumia.co.ke/televisions/#catalog-listing...\n",
      "Saved 50 products from https://www.jumia.co.ke/televisions/#catalog-listing to jumia_televisions table.\n",
      "Scraping URL: https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing\n",
      "Scraping page 1 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 2 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 3 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 4 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 5 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 6 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 7 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 8 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 9 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 10 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 11 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 12 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 13 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 14 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 15 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 16 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 17 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 18 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 19 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 20 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 21 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 22 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 23 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 24 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 25 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 26 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 27 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 28 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 29 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 30 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 31 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 32 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 33 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 34 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 35 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 36 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 37 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 38 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 39 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 40 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 41 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 42 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 43 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 44 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 45 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 46 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 47 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 48 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 49 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Scraping page 50 from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing...\n",
      "Saved 50 products from https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing to jumia_cookers table.\n"
     ]
    }
   ],
   "source": [
    "# Function to fetch and scrape product details from a single page\n",
    "def scrape_product_details(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    catalog_divs = soup.find_all('div', attrs={'data-catalog': 'true'})\n",
    "\n",
    "    products = []\n",
    "    for catalog_div in catalog_divs:\n",
    "        product = catalog_div.find('a', class_='core')\n",
    "        \n",
    "        if product:\n",
    "            name = product.find('h3', class_='name').get_text(strip=True) if product.find('h3', class_='name') else \"N/A\"\n",
    "            price = product.find('div', class_='prc').get_text(strip=True) if product.find('div', class_='prc') else \"N/A\"\n",
    "            old_price = product.find('div', class_='old').get_text(strip=True) if product.find('div', class_='old') else \"N/A\"\n",
    "            discount = product.find('div', class_='bdg _dsct _sm').get_text(strip=True) if product.find('div', class_='bdg _dsct _sm') else \"N/A\"\n",
    "            \n",
    "            rating = product.find('div', class_='rev')\n",
    "            if rating:\n",
    "                stars = rating.find('div', class_='stars _s').get_text(strip=True) if rating.find('div', class_='stars _s') else \"N/A\"\n",
    "                reviews_count = rating.get_text(strip=True).split('(')[-1].strip(')') if '(' in rating.get_text() else \"N/A\"\n",
    "            else:\n",
    "                stars = \"N/A\"\n",
    "                reviews_count = \"N/A\"\n",
    "\n",
    "            item_id = product.get('data-gtm-id', \"N/A\")\n",
    "            item_brand = product.get('data-gtm-brand', \"N/A\")\n",
    "            product_url = product['href'] if product.has_attr('href') else \"N/A\"\n",
    "\n",
    "            # Store product info in a dictionary\n",
    "            products.append({\n",
    "                \"product_name\": name,\n",
    "                \"price\": price,\n",
    "                \"old_price\": old_price,\n",
    "                \"discount\": discount,\n",
    "                \"rating\": f\"{stars} ({reviews_count} reviews)\",\n",
    "                \"item_id\": item_id,\n",
    "                \"item_brand\": item_brand,\n",
    "                \"product_url\": f\"https://www.jumia.co.ke{product_url}\"\n",
    "            })\n",
    "        \n",
    "        # Optional delay between requests\n",
    "        time.sleep(random.uniform(1, 3))  # Random delay between 1 and 3 seconds\n",
    "\n",
    "    return products\n",
    "\n",
    "# Function to get the last page number from the website using the 'Last Page' link\n",
    "def get_last_page_number(url, headers):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find the 'Last Page' link using its aria-label attribute\n",
    "    last_page_link = soup.find('a', attrs={'aria-label': 'Last Page'})\n",
    "    \n",
    "    if last_page_link and 'href' in last_page_link.attrs:\n",
    "        last_page_url = last_page_link['href']\n",
    "        try:\n",
    "            page_number = last_page_url.split('?page=')[1].split('#')[0]\n",
    "            return int(page_number)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting last page number: {e}\")\n",
    "            return 1  # Default to 1 if error occurs\n",
    "    else:\n",
    "        print(\"Last page link not found.\")\n",
    "        return 1  # Default to 1 page if no last page is found\n",
    "\n",
    "# Function to save data to PostgreSQL\n",
    "def save_to_postgresql(products, db_params, table_name):\n",
    "    try:\n",
    "        # Connect to your PostgreSQL database\n",
    "        conn = psycopg2.connect(**db_params)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Insert data into the specified table\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name} (product_name, price, old_price, discount, rating, item_id, item_brand, product_url)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "\n",
    "        for product in products:\n",
    "            cursor.execute(insert_query, (\n",
    "                product[\"product_name\"],\n",
    "                product[\"price\"],\n",
    "                product[\"old_price\"],\n",
    "                product[\"discount\"],\n",
    "                product[\"rating\"],\n",
    "                product[\"item_id\"],\n",
    "                product[\"item_brand\"],\n",
    "                product[\"product_url\"]\n",
    "            ))\n",
    "\n",
    "        # Commit the transaction\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Successfully inserted {len(products)} products into the {table_name} table.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "# Function to scrape and save data for a specific URL and table\n",
    "def scrape_and_save(url, headers, db_params, table_name):\n",
    "    print(f\"Scraping URL: {url}\")\n",
    "    \n",
    "    # Get the last page number for the current URL\n",
    "    last_page = get_last_page_number(url, headers)\n",
    "\n",
    "    # Initialize an empty list to store all products\n",
    "    products_list = []\n",
    "\n",
    "    # Iterate through all pages from 1 to the last page\n",
    "    for page_num in range(1, last_page + 1):\n",
    "        page_url = f\"{url}?page={page_num}#catalog-listing\"\n",
    "        print(f\"Scraping page {page_num} from {url}...\")\n",
    "\n",
    "        # Scrape the products from the current page\n",
    "        products = scrape_product_details(page_url, headers)\n",
    "        products_list.extend(products)  # Add the scraped products to the main list\n",
    "\n",
    "        # Sleep for a random time between requests to avoid overwhelming the server\n",
    "        time.sleep(random.uniform(1, 3))\n",
    "\n",
    "    # Save the products to PostgreSQL after scraping all pages for this URL\n",
    "    if products_list:\n",
    "        #save_to_postgresql(products_list, db_params, table_name)\n",
    "        print(f\"Saved {len(products_list)} products from {url} to {table_name} table.\")\n",
    "    else:\n",
    "        print(f\"No products found on {url}.\")\n",
    "\n",
    "# Define your headers and the URLs to scrape\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Define url1 and url2\n",
    "url1 = \"https://www.jumia.co.ke/televisions/#catalog-listing\"\n",
    "#url2 = \"https://www.jumia.co.ke/cookers/#catalog-listing\" \n",
    "url2 = \"https://www.jumia.co.ke/home-cooking-appliances-cookers/#catalog-listing\"\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    \"host\": \"localhost\",     # Database host\n",
    "    \"database\": \"e-analytics_db\",   # Database name\n",
    "    \"user\": \"postgres\",     # Database user\n",
    "    \"password\": \"password\"  # Database password\n",
    "}\n",
    "\n",
    "# Scrape and save data for both URLs\n",
    "scrape_and_save(url1, headers, db_params, \"jumia_televisions\")\n",
    "scrape_and_save(url2, headers, db_params, \"jumia_cookers\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e-analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
